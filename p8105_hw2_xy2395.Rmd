---
title: "p8105_hw2_xy2395"
author: "Jack Yan"
date: "9/27/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(p8105.datasets)
# data(package = 'p8105.datasets',  brfss_smart2010)
```

```{r}
library(tidyverse)
library(readxl)
library(p8105.datasets)
```

# Problem 1

## Data Import and Manipulation

```{r, message=F}
data_nysubway = 
  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(-division, -exit_only, -(staffing:staff_hours), -(ada_notes:entrance_location)) %>% 
  mutate( entry = recode(entry, "YES" = TRUE, "NO" = FALSE))

head(data_nysubway)
```

The code above 

* imported data from the `.csv` file, and cleaned up variable names using `clean_names` function. 
* It also selected variables to be used from the original dataset. Now the dataset contains variables of line, station name, station latitude & longitude, routes served, entrance type, entry, vending, and ADA compliance. 
* Further, it converted the entry variable from character (`YES` vs `NO`) to a logical variable. 
* The dataset has `r nrow(data_nysubway)` rows (observations) and  `r ncol(data_nysubway)` columns (variables).
* The data are not yet tidy, because the routes that each station supports are spead along variables from route1 to route11. I will fix this problem as instructed in Question 4.

A datailed list of variables in this dataset is shown below:

```{r}
# Show all the variables in data_nysubway
names(data_nysubway)
```


## Questions

### Question 1

How many distinct stations are there?
```{r}
data_nysubway = mutate(data_nysubway, station_name_line = paste(station_name, line))
distinct_station_name_line = distinct(data_nysubway, station_name_line)

# Count the rows in distinct_station_name_line
nrow(distinct_station_name_line)
```

There are `r nrow(distinct_station_name_line)` stations.

### Question 2

How many stations are ADA compliant?
```{r}
distinct_ada_compliant = 
  data_nysubway %>% 
  filter(ada == TRUE) %>% 
  distinct(station_name_line)

# Count the rows in distinct_ada_compliant
nrow(distinct_ada_compliant)
```

There are `r nrow(distinct_ada_compliant)` ADA compliant stations.

### Question 3

What proportion of station entrances / exits without vending allow entrance?
```{r}
# Number of entrances / exits without vending
n_without_vending =
  data_nysubway %>% 
  filter( vending == "NO") %>% 
  nrow()

# Number of entrances / exits without vending that allow entrance
n_without_vending_allow_entrance = 
  data_nysubway %>% 
  filter( vending == "NO") %>% 
  filter( entry == TRUE) %>% 
  nrow()

# Calculate the proportion this question asks for
n_without_vending_allow_entrance / n_without_vending
```

The proportion of station entrances / exits without vending allow entrance is `r round(n_without_vending_allow_entrance / n_without_vending, 2)`.

### Question 4
Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

The code below uses `gather` to tidy the data so that each value in the previous variables (from `route1` to `route11`) is gathered into a new variable `route_served`. Then filter out rows containing `NA`s in the `route_served` variable and delete the unnecessary `route_number` variable.

```{r}
# Tidy the dataset
tidy_data_nysubway = 
  gather(data_nysubway, key = route_number, value = route_served, route1:route11) %>% 
  filter(route_served != 'NA') %>% 
  select(-route_number)

# Count distinct stations serving the A train
tidy_data_nysubway %>% 
  filter(route_served == "A") %>% 
  distinct(station_name_line) %>% 
  nrow()

# Count ADA compliant stations that serve the A train
tidy_data_nysubway %>% 
  filter(route_served == "A") %>% 
  filter(ada == TRUE) %>% 
  distinct(station_name_line) %>% 
  nrow()
```

There are 60 distinct stations serving the A train, and 17 of them are ADA compliant.

# Problem 2
## Mr. Trash Wheel Dataset

Import the Mr. Trash Wheel dataset from the `.xlsx` file and clean the variable names, then omit rows that do not include dumpster-specific data. Further, round the number of sports balls to the nearest integer and converts the result to an integer variable using `as.integer`.

```{r}
data_mrtw = 
  read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",range = 'A2:N256') %>% 
  janitor::clean_names() %>% 
  filter(dumpster != "NA") %>% 
  mutate(sports_balls = as.integer(sports_balls))

head(data_mrtw)
```

## Precipitation Dataset

The following code trunk reads and cleans precipitation data for 2016 and 2017. For each, omit rows without precipitation data and add a variable year. Next, combine datasets and convert month to a character variable.

```{r}
data_prcpttn_2016 = 
    read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = '2016 Precipitation', range = "A2:B14") %>% 
    janitor::clean_names() %>% 
    filter(total != "NA") %>% 
    mutate(year = 2016)
    
data_prcpttn_2017 = 
    read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = '2017 Precipitation', range = "A2:B14")  %>% 
    janitor::clean_names() %>% 
    filter(total != "NA") %>% 
    mutate(year = 2017)

# Combine datasets for years 2016 and 2017
data_prcpttn = bind_rows(data_prcpttn_2016, data_prcpttn_2017) %>% 
    mutate(month = month.name[month]) %>% 
    select(year, month, total)

# Check the combined dataset
head(data_prcpttn)
```

## Interpretation
There are `r nrow(data_mrtw)` observations and `r ncol(data_mrtw)` variables in the Mr. Trash Wheel dataset, and `r nrow(data_prcpttn)` observations and `r ncol(data_prcpttn)` variables in the precipitation dataset. Key variables in the Mr. Trash Wheel dataset include `dumpster`, `weight_tons`, number of different items (such as `sports_balls`) and `homes_powered`. For the precipitation dataset, the key variable is `total`, which denotes the volumn of precipitation for each month. The total precipitation in 2017 was `r sum(filter(data_prcpttn_2017, year == 2017)$total)`. The median number of sports balls in a dumpster in 2016 was `r median(filter(data_mrtw, year == 2016)$sports_balls)`.

# Problem 3

## Data Import and Cleaning 
The following code trunk

* formats the data to use appropriate variable names using `clean_names()`,
* focuses on the “Overall Health” topic using `filter()`, and 
* excludes variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation using `select()`.
```{r}
tidy_brfss = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health")  %>% 
  select(-(class:question), -sample_size, -(confidence_limit_low : geo_location)) 
```

The following code trunk

* structures data so that responses (excellent to poor) are variables taking the value of `data_value`, using `spread()`,
* sort the variables from `excellent` to `poor`, and
* creates a new variable showing the proportion of responses that were “Excellent” or “Very Good”.

```{r}
structured_brfss = 
  tidy_brfss %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  select(year, locationabbr, locationdesc, excellent, very_good, good, fair, poor) %>% 
  mutate(excellent_and_very_good = excellent + very_good)
 
```

## Questions
### Summary of Answers
* There are `r distinct(structured_brfss, locationdesc) %>% nrow()` unique locations included in the dataset.
* There are `r distinct(structured_brfss, locationabbr) %>% nrow()` distinct locations in the variable `locationabbr`, representing all the 50 states and DC.
* `r (count(structured_brfss, locationabbr) %>% arrange(desc(n)))$locationabbr[1]` is observed the most.
* The median of the “Excellent” response value in 2002 was `r filter(structured_brfss, year == 2002)$excellent %>% median(na.rm = TRUE)`.

Code calculating these questions are shown below:

### Question 1

How many unique locations are included in the dataset?

```{r}
distinct(structured_brfss, locationdesc) %>% 
  nrow()
```

There are `r distinct(structured_brfss, locationdesc) %>% nrow()` unique locations (counties) in the dataset.

### Question 2

Is every state represented? 

```{r}
distinct_locations = distinct(structured_brfss, locationabbr) 

# number of distinct locations
nrow(distinct_locations)

# check if each state is represented
state.abb %in% distinct_locations$locationabbr 

# Why 51 distinct locations out of 50 states?
distinct_locations = 
(distinct_locations$locationabbr %in% state.abb) %>% 
  mutate(distinct_locations, is_state = .)
# Find out the 1 more location
distinct_locations$locationabbr[which(distinct_locations$is_state == FALSE)]
```

Yes, each of the 50 states is represented, and DC is also observed.

### Question 3

What state is observed the most?

```{r}
states_observed_ordered_list = 
  count(structured_brfss, locationabbr) %>% 
  arrange(desc(n)) 
head(states_observed_ordered_list)
# Full name of the state ranked 1st
state.name[which(state.abb == states_observed_ordered_list$locationabbr[1])]
```
NJ (New Jersy) is observed the most.

### Question 4

In 2002, what is the median of the “Excellent” response value?

```{r}
structured_brfss_2002 = filter(structured_brfss, year == 2002) 
median(structured_brfss_2002$excellent, na.rm = TRUE)
```

The median is `r median(structured_brfss_2002$excellent, na.rm = TRUE)`.

## Graphs
### Histogram

Make a histogram of “Excellent” response values in the year 2002.

```{r}
ggplot(structured_brfss_2002, aes(x = excellent)) + 
  geom_histogram(binwidth = 1, na.rm = T) 
```

### Scatterplot

Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r}
structured_brfss_ny = 
  structured_brfss %>% 
  filter(year>=2002, year<=2010) %>% 
  filter(locationdesc == "NY - Queens County" | locationdesc ==  "NY - New York County")

ggplot(structured_brfss_ny, aes(x = year, y = excellent, color = locationdesc)) + 
  geom_point() +
  geom_smooth (se = FALSE)
```


